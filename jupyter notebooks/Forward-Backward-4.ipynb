{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "written by Hamid Nemati 9535023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward-Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=3 # size of states space\n",
    "M=4 # size of oservations space\n",
    "T=5 # number of times we see an observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 3 3 0]\n"
     ]
    }
   ],
   "source": [
    "# generate a random sequence of observations\n",
    "# numpy.random.randint(low, high=None, size=None, dtype=int)\n",
    "O = np.random.randint(0,M,T)\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29422203 0.07484759 0.03951524 0.13112228]\n",
      " [0.44855994 0.39854757 0.34780568 0.39427893]\n",
      " [0.25721804 0.52660484 0.61267908 0.47459878]]\n"
     ]
    }
   ],
   "source": [
    "# observation matrix\n",
    "b = np.random.random((N,M))\n",
    "b /= np.array([b.sum(axis=0)]) \n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# probabilites for individual events have to sum to 1\n",
    "print(b.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29422203 0.44855994 0.25721804]\n",
      " [0.13112228 0.39427893 0.47459878]\n",
      " [0.13112228 0.39427893 0.47459878]\n",
      " [0.13112228 0.39427893 0.47459878]\n",
      " [0.29422203 0.44855994 0.25721804]]\n"
     ]
    }
   ],
   "source": [
    "# Given thes probabilities, we can easily estimate the observation probabilities in time.\n",
    "# we have 5 observation so we have 5 rows.\n",
    "# we have 3 states so we have 3 columns.\n",
    "ob=b.T[O]\n",
    "print(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24516257 0.42538428 0.32945316]\n",
      " [0.1551306  0.49998497 0.34488443]\n",
      " [0.31759074 0.28453531 0.39787395]]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#state transition matrix\n",
    "a = np.random.random((N,N))\n",
    "a /= np.array([a.sum(axis=-1)]).T\n",
    "print(a)\n",
    "print(a.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56694725 0.27998804 0.15306471]\n"
     ]
    }
   ],
   "source": [
    "# generate the priors\n",
    "pi = np.random.random(N)\n",
    "pi /= pi.sum()\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm =(O,pi,a,b,N,M,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16680837 0.12559142 0.03937101]\n",
      " [0.00955647 0.05715228 0.0540733 ]\n",
      " [0.00372153 0.01893572 0.0210597 ]\n",
      " [0.0013818  0.00671965 0.00765804]\n",
      " [0.00112196 0.0027481  0.00149693]]\n"
     ]
    }
   ],
   "source": [
    "def forward(O,pi,a,b,N,M,T):\n",
    "    fwd = np.zeros((T,N))\n",
    "\n",
    "    #initialization\n",
    "    fwd[0] = pi*b[:,O[0]]\n",
    "\n",
    "    #induction:\n",
    "    for t in range(T-1):\n",
    "        fwd[t+1] = np.dot(fwd[t],a)*b[:,O[t+1]]\n",
    "    \n",
    "    return fwd\n",
    "\n",
    "print(forward(*hmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005366989247259792\n"
     ]
    }
   ],
   "source": [
    "# sum of all the forward probabilities at the last time step\n",
    "def full_prob(fwd):\n",
    "    return fwd[-1].sum()\n",
    "\n",
    "print(full_prob(forward(*hmm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01583352 0.01700768 0.01498074]\n",
      " [0.04394399 0.04719749 0.04160271]\n",
      " [0.12189395 0.1307065  0.11578202]\n",
      " [0.34768387 0.35862656 0.32341369]\n",
      " [1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def backward(O,pi,a,b,N,M,T):\n",
    "    bk=np.zeros((T,N))\n",
    "    \n",
    "    #initialization:\n",
    "    bk[T-1] = 1\n",
    "    \n",
    "    #induction:\n",
    "    for t in reversed(range(T-1)):\n",
    "        bk[t] = np.dot(bk[t+1]*b[:,O[t+1]],a.T)\n",
    "    return bk\n",
    "\n",
    "print(backward(*hmm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have both Forward and Backward probabilities computed, we can use them together to estimate the probability of each state, at each point in time, by simply multuplying those two probablilities together. Addtionally, we normalize this by the joint probability $P$ to make sure everything sums up nicely (i.e. each timestep sums to 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49211274 0.39799197 0.10989528]\n",
      " [0.07824673 0.50259912 0.41915415]\n",
      " [0.08452263 0.46115656 0.45432082]\n",
      " [0.08951567 0.44901254 0.46147179]\n",
      " [0.20904832 0.51203824 0.27891344]]\n"
     ]
    }
   ],
   "source": [
    "def gamma(fwd,bk,fp):\n",
    "    return (fwd*bk)/fp\n",
    "\n",
    "print(gamma(forward(*hmm),backward(*hmm),full_prob(forward(*hmm))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# d(t, i): path with the highest probability of seeing the first t observation then ending in State i\n",
    "# ph(t, i): if we are in state i in time t, what is the privious state?\n",
    "def viterbi(O,pi,a,b,N,M,T):\n",
    "    d = np.zeros((T,N))\n",
    "    ph = np.zeros((T,N), dtype=np.int)\n",
    "\n",
    "    #initialization\n",
    "    d[0] = pi*b[:,O[0]]\n",
    "    ph[0] = 0\n",
    "\n",
    "    #recursion\n",
    "    for t in range(1,T):\n",
    "        m = d[t-1] * a.T        \n",
    "        ph[t] = m.argmax(axis=1)\n",
    "        d[t] = m[np.arange(N), ph[t]] * b[:,O[t]]    \n",
    "\n",
    "    #termination\n",
    "    Q = np.zeros(T,dtype=np.int)\n",
    "    Q[T-1] = np.argmax(d[T-1])\n",
    "    Pv = d[T-1, Q[T-1]]\n",
    "\n",
    "    #path back-tracking\n",
    "    for t in reversed(range(T-1)):\n",
    "        Q[t] = ph[t+1, Q[t+1]]\n",
    "\n",
    "    return Q\n",
    "\n",
    "print(viterbi(*hmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best observation sequence: [1 2 2 2 1]\n",
      "Best forward prob. sequence: [0 1 2 2 1]\n",
      "Best backward prob. sequence: [1 1 1 1 0]\n",
      "Best full prob. sequence: [0 1 1 2 1]\n",
      "Best Viterbi sequence: [0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print('Best observation sequence: {}'.format(np.argmax(ob,axis=1)))\n",
    "print('Best forward prob. sequence: {}'.format(np.argmax(forward(*hmm),axis=1)))\n",
    "print('Best backward prob. sequence: {}'.format(np.argmax(backward(*hmm),axis=1)))\n",
    "g = gamma(forward(*hmm),backward(*hmm),full_prob(forward(*hmm)))\n",
    "print('Best full prob. sequence: {}'.format(np.argmax(g,axis=1)))\n",
    "print('Best Viterbi sequence: {}'.format(viterbi(*hmm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baum-Welch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also determine the sequence probablity, which would help us with fine-tuning the state transition likelihood.\n",
    "\n",
    "The transition probability computed for each timestep gives us a 3D matrix of size 4x3x3, since there are $N^2$ transitions at each timestep and only $T-1$ transitions time steps (i.e. number of transitions between 5 consecutive timesteps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.04390533 0.24603168 0.20217573]\n",
      "  [0.02091716 0.21772519 0.15934963]\n",
      "  [0.01342424 0.03884225 0.05762879]]\n",
      "\n",
      " [[0.00697717 0.03903452 0.03223503]\n",
      "  [0.02640334 0.2743851  0.20181068]\n",
      "  [0.05114211 0.14773693 0.2202751 ]]\n",
      "\n",
      " [[0.00775008 0.0417079  0.03506465]\n",
      "  [0.02495225 0.24943315 0.18677115]\n",
      "  [0.05681335 0.15787149 0.23963598]]\n",
      "\n",
      " [[0.01857137 0.04912657 0.02181773]\n",
      "  [0.05714637 0.28079764 0.11106853]\n",
      "  [0.13333058 0.18211403 0.14602718]]]\n"
     ]
    }
   ],
   "source": [
    "# The transition probability computed for each timestep\n",
    "def xi(fwd,bk,fp,O,pi,a,b,N,M,T):\n",
    "    return  fwd[:-1].reshape((T-1,N,1))*\\\n",
    "            a.reshape((1,N,N))*\\\n",
    "            b[:,O[1:]].T.reshape((T-1,1,N))*\\\n",
    "            bk[1:].reshape((T-1,1,N))/fp\n",
    "\n",
    "print(xi(forward(*hmm),backward(*hmm),full_prob(forward(*hmm)),*hmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49211274 0.39799197 0.10989528]\n"
     ]
    }
   ],
   "source": [
    "# The expected prior value can be estimated by simply looking at the \n",
    "# expected value (gamma) at the first point in time\n",
    "def exp_pi(gamma):\n",
    "    return gamma[0]\n",
    "\n",
    "print(exp_pi(gamma(forward(*hmm),backward(*hmm),full_prob(forward(*hmm)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1037133  0.50497286 0.39131383]\n",
      " [0.07147226 0.5645922  0.36393554]\n",
      " [0.17628936 0.36444448 0.45926616]]\n"
     ]
    }
   ],
   "source": [
    "# The expected transistions is the sum (for different timestep) of transition \n",
    "# probabilities xi normalized by the corresponding emitting state probabilities\n",
    "def exp_a(gamma,xi,N):            \n",
    "    return xi[:].sum(axis=0)/gamma[:-1].sum(axis=0).reshape(N,1)\n",
    "\n",
    "fw = forward(*hmm)\n",
    "bk = backward(*hmm)\n",
    "fp = full_prob(fw)\n",
    "g  = gamma(fw,bk,fp)\n",
    "x  = xi(fw,bk,fp,*hmm)\n",
    "\n",
    "print(exp_a(g,x,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73539665 0.         0.         0.26460335]\n",
      " [0.39178183 0.         0.         0.60821817]\n",
      " [0.22555909 0.         0.         0.77444091]]\n"
     ]
    }
   ],
   "source": [
    "# the expected observation likelihood is sum of probabilities of given states at times where\n",
    "# the specific observation occured normalized by the sum of all the probilities in time \n",
    "# for the given state\n",
    "def exp_b(gamma,O,N,M):    \n",
    "    return np.array(list(map(lambda k: np.sum(gamma[O==k],axis=0)/np.sum(gamma,axis=0), np.arange(M)))).T\n",
    "\n",
    "fw = forward(*hmm)\n",
    "bk = backward(*hmm)\n",
    "fp = full_prob(fw)\n",
    "g  = gamma(fw,bk,fp)\n",
    "\n",
    "print(exp_b(g,O,N,M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Baum-Welch algorithm now works by repeadatly updating the model parameters in this two step EM (first Expectation, then Modification) procedure. The goal of the algorithm is to maximize the $P(O|\\Lambda)$, where $O$ is the observation sequence and $\\Lambda$ is the model. We will also print out the mean square of the difference of model parameters vs their expected value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial probability: 0.005366989247259792\n",
      "Update #1 probability: 0.051064857052248995 -- mean error: 0.05771785410418955\n",
      "Update #2 probability: 0.07094211999280131 -- mean error: 0.00396883133331852\n",
      "Update #3 probability: 0.09603175883786529 -- mean error: 0.003350119865485326\n",
      "Update #4 probability: 0.11277771061930612 -- mean error: 0.0012735524504434638\n",
      "Update #5 probability: 0.1204017979465175 -- mean error: 0.0003245524207321524\n",
      "Update #6 probability: 0.1246232203473026 -- mean error: 0.0001649316486886098\n",
      "Update #7 probability: 0.1280278518201862 -- mean error: 0.00015484004081682884\n",
      "Update #8 probability: 0.13143492544939248 -- mean error: 0.00017666660529634364\n",
      "Update #9 probability: 0.13527159603211697 -- mean error: 0.0002279714869739399\n",
      "Update #10 probability: 0.14019818530610198 -- mean error: 0.0003295356487009543\n",
      "Update #11 probability: 0.14763507881067328 -- mean error: 0.0005166788857658726\n",
      "Update #12 probability: 0.16028413376542416 -- mean error: 0.0008040879841357417\n",
      "Update #13 probability: 0.18167493208213165 -- mean error: 0.0010679505379534366\n",
      "Update #14 probability: 0.2123878795879097 -- mean error: 0.0010371750081777742\n",
      "Update #15 probability: 0.24516159625273828 -- mean error: 0.0007473971012763404\n"
     ]
    }
   ],
   "source": [
    "print('Initial probability: {}'.format(full_prob(forward(*hmm))))\n",
    "\n",
    "hmm_new=hmm\n",
    "for i in range(15):\n",
    "    fw = forward(*hmm_new)\n",
    "    bk = backward(*hmm_new)\n",
    "    fp = full_prob(fw)\n",
    "    g  = gamma(fw,bk,fp)\n",
    "    x  = xi(fw,bk,fp,*hmm_new)\n",
    "\n",
    "    pi_new = exp_pi(g)\n",
    "    a_new  = exp_a(g,x,N)\n",
    "    b_new  = exp_b(g,O,N,M)\n",
    "    \n",
    "    err = np.concatenate(((pi_new-hmm_new[1]).ravel(),(a_new-hmm_new[2]).ravel(),(b_new-hmm_new[3]).ravel()))    \n",
    "\n",
    "    hmm_new = (O,pi_new,a_new,b_new,N,M,T)\n",
    "\n",
    "    print('Update #{} probability: {} -- mean error: {}'.format(i+1,full_prob(forward(*hmm_new)),np.mean(err**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
